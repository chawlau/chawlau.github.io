<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>  
	  
  	Linux性能优化实战 -        凌云阁
  	
	</title>

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link href="atom.xml" rel="alternate" title="       凌云阁" type="application/atom+xml">

	<link href="asset/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="asset/stylesheets/font-awesome.min.css" media="screen, projection" rel="stylesheet" type="text/css">
	<script src="asset/javascripts/jquery.min.js"></script>
	<script src="asset/highlightjs/highlight.pack.js"></script>
	<link href="asset/highlightjs/styles/solarized_dark.css" media="screen, projection" rel="stylesheet" type="text/css">
<script>hljs.initHighlightingOnLoad();</script>

	<!--[if lt IE 9]><script src="asset/javascripts/html5.js"></script><![endif]-->
	<!-- <link href='http://fonts.googleapis.com/css?family=Nunito:400,300,700' rel='stylesheet' type='text/css'> -->
	<style type="text/css">
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 300;
  src: local('Nunito-Light'), url(asset/font/1TiHc9yag0wq3lDO9cw0voX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 400;
  src: local('Nunito-Regular'), url(asset/font/6TbRXKWJjpj6V2v_WyRbMX-_kf6ByYO6CLYdB4HQE-Y.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 700;
  src: local('Nunito-Bold'), url(asset/font/TttUCfJ272GBgSKaOaD7KoX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
	</style>
	
	<style type="text/css">
	.container .left-col{ opacity: 1;}
	#pagenavi a{ font-size: 1.3em;}
	#pagenavi .next:before{ top: 3px;}
	#pagenavi .prev:before{ top: 3px;}
	.container .mid-col .mid-col-container #content .archives .title{ font-size: 1.5em;}
	.container .mid-col .mid-col-container #content article{ padding: 15px 0px;}
	#header .subtitle {
		line-height: 1.2em;
		padding-top: 8px;
	}
	article pre{ background: none; border: none; padding: 0;}
	article .entry-content{text-align: left;}
	.share-comment{ padding: 25px 0px; clear: both;}
	hr{ margin: 20px 0px;border: 0; border-top:solid 1px #ddd;}

	</style>
  

</head>


<body>
	<div class="container">
		<div class="left-col">
			<div class="intrude-less">
				<header id="header" class="inner">
				 
				 	<div class="profilepic">
						<img src="https://i.loli.net/2020/02/22/Si1K7sluept2ZgR.jpg" style="width:160px;">
					</div>
            	
					
					<h1><a href="index.html">       凌云阁</a></h1>
					<p class="subtitle">生命的意义是成为你自己！</p>
					<nav id="main-nav">
						<ul class="main">
						
						  <li id=""><a target="_self" href="index.html">Home</a></li>
						
						  <li id=""><a target="_self" href="archives.html">Archives</a></li>
						
						</ul>
					</nav>

					<nav id="sub-nav">
						<div class="social">

<a target="_blank" class="facebook" href="www.facebook.com" title="Facebook">Facebook</a>






<a target="_blank" class="weibo" href="www.weibo.com" title="weibo">Weibo</a>
<a target="_blank" class="twitter" target="_blank" href="www.twitter.com" title="Twitter">Twitter</a>
<a target="_blank" class="github" target="_blank" href="www.github.com/chawlau" title="GitHub">GitHub</a>


								

								<a class="rss" href="atom.xml" title="RSS">RSS</a>
							
						</div>
					</nav>
				</header>				
			</div>
		</div>	
		<div class="mid-col">
			<div class="mid-col-container"> <div id="content" class="inner">
<div itemscope itemtype="http://schema.org/Blog">


	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2019-03-01T09:30:48+08:00" itemprop="datePublished">2019/03/01 09:30 上午</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98.html'>Linux性能优化实战</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="15514038480126.html" itemprop="url">
		网络性能优化套路</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h4><a id="%E4%BC%98%E5%8C%96%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>优化性能指标</h4>
<ul>
<li>整体目标，是降低网络延迟（如 RTT）和提高吞吐量BPS和PPS</li>
<li>NAT网关需要接近线性转发，PPS是最主要性能目标</li>
<li>数据库和缓存系统,低延迟是主要目标</li>
<li>Web服务要兼顾吞吐量和延迟</li>
</ul>
<h4><a id="%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%A0%88%E5%90%84%E5%B1%82%E7%BA%A7%E7%9B%AE%E6%A0%87" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>网络协议栈各层级目标</h4>
<ul>
<li>网络接口层和网络层，PPS是主要性能指标， 使用pkten来测试PPS</li>
<li>测试教程 <a href="http://khalily.github.io/2015/05/03/pktgen/">http://khalily.github.io/2015/05/03/pktgen/</a></li>
<li>TCP UDP 吞吐量和连接数以及延迟 iperf和netperf</li>
<li>ICMP hping3 ping</li>
<li>应用层 吞吐量，每秒请求数和延迟wrk,ab</li>
</ul>
<h4><a id="%E5%B7%A5%E5%85%B7%E5%92%8C%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E7%9A%84%E5%AF%B9%E5%BA%94" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>工具和性能指标的对应</h4>
<ul>
<li><img src="media/15514038480126/a1eb07e281e5795be83c11d7255c543b.png" alt="a1eb07e281e5795be83c11d7255c543b" /></li>
<li><img src="media/15514038480126/0d87b39b89a1b7f325fc5477c0182ea0.png" alt="0d87b39b89a1b7f325fc5477c0182ea0" /></li>
</ul>
<h4><a id="%E7%BD%91%E7%BB%9C%E6%94%B6%E5%8F%91%E6%B5%81%E7%A8%8B" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>网络收发流程</h4>
<ul>
<li><img src="media/15514038480126/a118911721f9b67ce9c83de15666753f.png" alt="a118911721f9b67ce9c83de15666753f" /></li>
</ul>
<h4><a id="%E5%BA%94%E7%94%A8%E5%B1%82%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E4%BC%98%E5%8C%96" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>应用层网络协议优化</h4>
<ul>
<li>使用长连接取代短连接，可以显著降低 TCP 建立连接的成本。在每秒请求次数较多时，这样做的效果非常明显。</li>
<li>使用内存等方式，来缓存不常变化的数据，可以降低网络 I/O 次数，同时加快应用程序的响应速度。</li>
<li>使用 Protocol Buffer 等序列化的方式，压缩网络 I/O 的数据量，可以提高应用程序的吞吐。</li>
<li>使用 DNS 缓存、预取、HTTPDNS 等方式，减少 DNS 解析的延迟，也可以提升网络 I/O 的整体速度。</li>
</ul>
<h4><a id="%E5%A5%97%E6%8E%A5%E5%AD%97%E5%86%85%E6%A0%B8%E9%80%89%E9%A1%B9" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>套接字内核选项</h4>
<ul>
<li><img src="media/15514038480126/708e766b878d9b32bcdaafb21f0a657f.png" alt="708e766b878d9b32bcdaafb21f0a657f" /></li>
<li>TCP优化</li>
<li>为 TCP 连接设置 TCP_NODELAY 后，就可以禁用 Nagle 算法；</li>
<li>为 TCP 连接开启 TCP_CORK 后，可以让小包聚合成大包后再发送（注意会阻塞小包的发送）；</li>
<li>使用 SO_SNDBUF 和 SO_RCVBUF ，可以分别调整套接字发送缓冲区和接收缓冲区的大小。</li>
</ul>
<h4><a id="%E4%BC%A0%E8%BE%93%E5%B1%82%E4%BC%98%E5%8C%96" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>传输层优化</h4>
<ul>
<li>配置参数在/etc/sysctl.conf</li>
</ul>
<h5><a id="%E5%A4%84%E7%90%86time-wait" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>处理TIME_WAIT</h5>
<ul>
<li>增大处于 TIME_WAIT 状态的连接数量 net.ipv4.tcp_max_tw_buckets ，并增大连接跟踪表的大小 net.netfilter.nf_conntrack_max。</li>
<li>减小 net.ipv4.tcp_fin_timeout 和 net.netfilter.nf_conntrack_tcp_timeout_time_wait ，让系统尽快释放它们所占用的资源。</li>
<li>开启端口复用 net.ipv4.tcp_tw_reuse。这样，被 TIME_WAIT 状态占用的端口，还能用到新建的连接中。</li>
<li>增大本地端口的范围 net.ipv4.ip_local_port_range 。这样就可以支持更多连接，提高整体的并发能力。</li>
<li>增加最大文件描述符的数量。你可以使用 fs.nr_open ，设置系统的最大文件描述符数；或在应用程序的 systemd 配置文件中，配置 LimitNOFILE ，设置应用程序的最大文件描述符数。</li>
</ul>
<h5><a id="syn%E7%8A%B6%E6%80%81%E4%BC%98%E5%8C%96" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>SYN状态优化</h5>
<ul>
<li>增大 TCP 半连接的最大数量 net.ipv4.tcp_max_syn_backlog ，或者开启 TCP SYN Cookies net.ipv4.tcp_syncookies ，来绕开半连接数量限制的问题（注意，这两个选项不可同时使用）。</li>
<li>减少 SYN_RECV 状态的连接重传 SYN+ACK 包的次数 net.ipv4.tcp_synack_retries。</li>
</ul>
<h4><a id="%E9%85%8D%E7%BD%AE%E4%B8%8Ekeepalive%E9%80%89%E9%A1%B9" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>配置与Keepalive选项</h4>
<ul>
<li>缩短最后一次数据包到 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_time；</li>
<li>缩短发送 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_intvl；</li>
<li>减少 Keepalive 探测失败后，一直到通知应用程序前的重试次数 net.ipv4.tcp_keepalive_probes。</li>
</ul>
<h5><a id="tcp%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>tcp优化总结</h5>
<ul>
<li><img src="media/15514038480126/38c164bcd76d426c215fad997ecfd396.png" alt="38c164bcd76d426c215fad997ecfd396" /></li>
</ul>
<h4><a id="udp%E4%BC%98%E5%8C%96" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>UDP优化</h4>
<ul>
<li>跟上篇套接字部分提到的一样，增大套接字缓冲区大小以及 UDP 缓冲区范围。</li>
<li>跟前面 TCP 部分提到的一样，增大本地端口号的范围；</li>
<li>根据 MTU 大小，调整 UDP 数据包的大小，减少或者避免分片的发生。</li>
</ul>
<h4><a id="%E7%BD%91%E7%BB%9C%E5%B1%82" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>网络层</h4>
<h5><a id="%E8%B7%AF%E7%94%B1%E8%BD%AC%E5%8F%91" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>路由转发</h5>
<ul>
<li>开启ip转发  net.ipv4.ip_forward = 1</li>
<li>调整数据包的生存周期 TTL，比如设置 net.ipv4.ip_default_ttl = 64</li>
<li>开启数据包的反向地址校验，比如设置 net.ipv4.conf.eth0.rp_filter = 1。这样可以防止 IP 欺骗，并减少伪造 IP 带来的 DDoS 问题</li>
</ul>
<h6><a id="%E5%88%86%E7%89%87" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>分片</h6>
<ul>
<li>从分片的角度出发，最主要的是调整 MTU（Maximum Transmission Unit）的大小。</li>
</ul>
<h5><a id="%E9%99%90%E5%88%B6icmp%E7%9A%84%E8%A1%8C%E4%B8%BA" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>限制ICMP的行为</h5>
<ul>
<li>禁止 ICMP 协议，即设置 net.ipv4.icmp_echo_ignore_all = 1。这样，外部主机就无法通过 ICMP 来探测主机</li>
<li>禁止广播 ICMP，即设置 net.ipv4.icmp_echo_ignore_broadcasts = 1</li>
</ul>
<h4><a id="%E9%93%BE%E8%B7%AF%E5%B1%82" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>链路层</h4>
<ul>
<li>网卡硬中断配置 CPU 亲和性（smp_affinity），或者开启 irqbalance 服务。</li>
<li>开启 RPS（Receive Packet Steering）和 RFS（Receive Flow Steering），将应用程序和软中断的处理，调度到相同 CPU 上，这样就可以增加 CPU 缓存命中率，减少网络延迟</li>
<li>TSO和UFO让TCP包的分段和UDP的分片由网卡来完成</li>
<li>GSO将分包分片延迟到进入网卡前</li>
<li>LRO接收TCP分段包时由网卡进行组装合并后交给上层处理</li>
<li>GRO支持TCP和UDP组装的</li>
<li>RSS多队列接收，基于硬件的多个队列接收，分配网络接收进程，让多CPU处理接收到的包</li>
<li>VXLALN卸载，让网卡来完成VXLAN的组包功能</li>
</ul>
<h4><a id="%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>网络接口</h4>
<ul>
<li>开启网络接口的多队列功能</li>
<li>增大网络接口的缓冲区大小</li>
<li>使用TC为不同网络流量配置Qos</li>
<li></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2019-03-20T09:37:54+08:00" itemprop="datePublished">2019/03/20 09:37 上午</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98.html'>Linux性能优化实战</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="15530458747105.html" itemprop="url">
		Linux内核线程</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h4><a id="%E7%89%B9%E6%AE%8A%E8%BF%9B%E7%A8%8B" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>特殊进程</h4>
<ul>
<li>0 号进程为 idle 进程，这也是系统创建的第一个进程，它在初始化 1 号和 2 号进程后，演变为空闲任务。当 CPU 上没有其他任务执行时，就会运行它。</li>
<li>1 号进程为 init 进程，通常是 systemd 进程，在用户态运行，用来管理其他用户态进程。</li>
<li>2 号进程为 kthreadd 进程，在内核态运行，用来管理内核线程。</li>
</ul>
<h4><a id="%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>内核线程</h4>
<ul>
<li>kswapd0：用于内存回收。在 Swap 变高 案例中，我曾介绍过它的工作原理。</li>
<li>kworker：用于执行内核工作队列，分为绑定 CPU （名称格式为 kworker/CPU86330）和未绑定 CPU（名称格式为 kworker/uPOOL86330）两类。</li>
<li>migration：在负载均衡过程中，把进程迁移到 CPU 上。每个 CPU 都有一个 migration 内核线程。</li>
<li>jbd2/sda1-8：jbd 是 Journaling Block Device 的缩写，用来为文件系统提供日志功能，以保证数据的完整性；名称中的 sda1-8，表示磁盘分区名称和设备号。每个使用了 ext4 文件系统的磁盘分区，都会有一个 jbd2 内核线程。</li>
<li>pdflush：用于将内存中的脏页（被修改过，但还未写入磁盘的文件页）写入磁盘（已经在 3.10 中合并入了 kworker 中）</li>
</ul>
<h4><a id="%E5%AE%9E%E9%AA%8C" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>实验</h4>
<ul>
<li>perf record -a -g -p 9 -- sleep 30<br />
<img src="media/15530458747105/15530482433793.jpg" alt="" style="width:1166px;" /></li>
</ul>
<h4><a id="ksoftirqd%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>ksoftirqd调用流程</h4>
<ul>
<li>net_rx_action 和 netif_receive_skb，表明这是接收网络包（rx 表示 receive）。</li>
<li>br_handle_frame ，表明网络包经过了网桥（br 表示 bridge）。</li>
<li>br_nf_pre_routing ，表明在网桥上执行了 netfilter 的 PREROUTING（nf 表示 netfilter）。而我们已经知道 PREROUTING 主要用来执行 DNAT，所以可以猜测这里有 DNAT 发生。</li>
<li>br_pass_frame_up，表明网桥处理后，再交给桥接的其他桥接网卡进一步处理。比如，在新的网卡上接收网络包、执行 netfilter 过滤规则等等。</li>
</ul>
<h4><a id="%E7%94%9F%E6%88%90%E7%81%AB%E7%84%B0%E5%9B%BE" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>生成火焰图</h4>
<ul>
<li>perf script -i /root/perf.data | ./stackcollapse-perf.pl --all |  ./flamegraph.pl &gt; ksoftirqd.svg</li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2018-12-24T09:54:36+08:00" itemprop="datePublished">2018/12/24 09:54 上午</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98.html'>Linux性能优化实战</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="15456164768088.html" itemprop="url">
		Linux内存工作机制</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h4><a id="%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>内存映射</h4>
<ul>
<li>每个进程都有很大的地址空间</li>
<li>并不是所有的虚拟内存都会分配物理内存，只有那些实际使用的虚拟内存才分配物理内存，并且分配后的物理内存，是通过内存映射来管理的。</li>
<li>将虚拟内存地址映射到物理内存地址。为了完成内存映射，内核为每个进程都维护了一张页表，记录虚拟地址与物理地址的映射关系</li>
</ul>
<h4><a id="%E7%BC%BA%E9%A1%B5%E5%BC%82%E5%B8%B8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>缺页异常</h4>
<ul>
<li>进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行</li>
</ul>
<h4><a id="%E8%A7%A3%E5%86%B3%E9%A1%B5%E8%A1%A8%E8%BF%87%E5%A4%9A" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>解决页表过多</h4>
<ul>
<li>多级页表</li>
<li>大页面</li>
</ul>
<h4><a id="%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>虚拟内存空间</h4>
<p><img src="media/15456164768088/15456168238060.jpg" alt="" /></p>
<ul>
<li>文件映射包括动态库，共享内存</li>
</ul>
<h4><a id="malloc%E5%86%85%E5%AD%98" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>malloc内存</h4>
<ul>
<li>
<blockquote>
<p>128K 使用mmap mmap() 方式分配的内存，会在释放时直接归还系统，所以每次 mmap 都会发生缺页异常。在内存工作繁忙时，频繁的内存分配会导致大量的缺页异常，使内核的管理负担增大。这也是 malloc 只对大块内存使用 mmap 的原因。</p>
</blockquote>
</li>
<li>&lt;128K 使用brk brk() 方式的缓存，可以减少缺页异常的发生，提高内存访问效率。不过，由于这些内存没有归还系统，在内存工作繁忙时，频繁的内存分配和释放会造成内存碎片。</li>
<li>slab是内核空间的，只用来管理内核中的小块内存</li>
</ul>
<h4><a id="%E7%AE%A1%E7%90%86%E5%B0%8F%E5%86%85%E5%AD%98" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>管理小内存</h4>
<ul>
<li>slab管理器管理小内存</li>
</ul>
<h4><a id="%E7%B3%BB%E7%BB%9F%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>系统回收机制</h4>
<ul>
<li>回收缓存，比如使用 LRU（Least Recently Used）算法，回收最近使用最少的内存页面；</li>
<li>回收不常访问的内存，把不常用的内存通过交换分区直接写到磁盘中；</li>
<li>杀死进程，内存紧张时系统还会通过 OOM（Out of Memory），直接杀掉占用大量内存的进程。oom_adj的范围-17~15</li>
</ul>
<h4><a id="top" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>top</h4>
<ul>
<li>VIRT 进程虚拟内存的大小，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内。</li>
<li>RES 是常驻内存的大小，也就是进程实际使用的物理内存大小</li>
<li>SHR 是共享内存的大小，比如与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等。</li>
<li>共享内存 SHR 并不一定是共享的，比方说，程序的代码段、非共享的动态链接库，也都算在 SHR 里。当然，SHR 也包括了进程间真正共享的内存。所以在计算多个进程的内存使用时，不要把所有进程的 SHR 直接相加得出结果</li>
</ul>
<h4><a id="%E6%9F%A5%E7%9C%8B%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E6%83%85%E5%86%B5" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>查看系统内存情况</h4>
<ul>
<li>cat /proc/[pid]/status和pmap -x pid</li>
</ul>
<h4><a id="%E6%8B%93%E5%B1%95%E9%98%85%E8%AF%BB" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>拓展阅读</h4>
<ul>
<li><a href="https://blog.holbertonschool.com/hack-the-virtual-memory-malloc-the-heap-the-program-break/">https://blog.holbertonschool.com/hack-the-virtual-memory-malloc-the-heap-the-program-break/</a></li>
</ul>
<h4><a id="%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>内存分配</h4>
<ul>
<li>调用c标准库的都是用户空间的调用，用户空间的内存分配都是基于buddy算法（伙伴算法），并不涉及slab</li>
<li>brk()方式之所以会产生内存碎片，是由于brk分配的内存是推_edata指针，从堆的低地址向高地址推进。这种情况下，如果高地址的内存不释放，低地址的内存是得不到释放的</li>
<li>mmap()方式分配的内存，是在堆与栈之间的空闲区域分配虚拟内存，直接拿到的是内存地址，可以直接操作内存的释放</li>
<li>上述的都是在用户空间发生的行为，只有在内核空间，内核调用kmalloc去分配内存的时候，才会涉及到slab</li>
</ul>
<h4><a id="%E7%BC%BA%E9%A1%B5%E5%BC%82%E5%B8%B8" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>缺页异常</h4>
<ul>
<li>缺页异常是内存分配必要步骤：陷入内核态分配内存并完成内存映射的过程</li>
<li>可以直接从物理内存中分配时，被称为次缺页异常。</li>
<li>需要磁盘 I/O 介入（比如 Swap）时，被称为主缺页异常。</li>
</ul>
<h4><a id="oom-score" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>oom_score</h4>
<ul>
<li>一个进程消耗的内存越大，oom_score 就越大；</li>
<li>一个进程运行占用的 CPU 越多，oom_score 就越小。</li>
<li>通过oom_adj来调整大小</li>
</ul>
<h4><a id="%E7%BC%93%E5%AD%98" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>缓存</h4>
<ul>
<li>cachestat 系统缓存和缓冲区的命中率</li>
<li>cachetop 进程缓存和缓冲区的命中率</li>
</ul>
<h4><a id="%E5%86%85%E5%AD%98%E9%80%89%E9%A1%B9" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>内存选项</h4>
<ul>
<li>RSS (Resident set size），使用 top 命令可以查询到，是最常用的内存指标，表示进程占用的物理内存大小。但是，将各进程的 RSS 值相加，通常会超出整个系统的内存消耗，这是因为 RSS 中包含了各进程间共享的内存。</li>
<li>PSS (Proportional set size）所有使用某共享库的程序均分该共享库占用的内存时。显然所有进程的 PSS 之和就是系统的内存使用量。它会更准确一些，它将共享内存的大小进行平均后，再分推到各进程上去。</li>
<li>USS (Unique set size）进程独自占用的内存，它只计算了进程独自占用的内存大小，</li>
<li>smem -k  -s uss</li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2019-10-03T17:46:36+08:00" itemprop="datePublished">2019/10/03 17:46 下午</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98.html'>Linux性能优化实战</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="15700959965580.html" itemprop="url">
		应对DDos攻击和TFO</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h4><a id="ddos%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>DDos参数配置</h4>
<ul>
<li>/proc/sys/net/ipv4/tcp_syncookies</li>
<li>/proc/sys/net/ipv4/tcp_max_syn_backlog</li>
<li>/proc/sys/net/ipv4/tcp_synack_retries</li>
<li>当 SYN 队列满后，新的 SYN 不进入队列，计算出 cookie 再以 SYN+ACK 中的序列号返回客户端，正常客户端发报文时，服务器根据报文中携带的 cookie 重新恢复连接</li>
<li>当 SYN 队列满后，新的 SYN 不进入队列，计算出 cookie 再以 SYN+ACK 中的序列号返回客户端，正常客户端发报文时，服务器根据报文中携带的 cookie 重新恢复连接</li>
<li>由于cookies 占用序列号空间，导致此时所有 TCP 可选功能失效，例如扩充窗口、时间戳等</li>
<li>tcp_syncookies只有在队列满了之后才使用，防止ddos攻击</li>
<li>SYN-Cookie避免了内存空间被爆掉，但是却引来了CPU时间被爆掉的机会，这又是一种时间-空间之间的权衡！如果攻击者发送大量的ACK包过来，那么被攻击机器将会花费大量的CPU时间在计算Cookie上，造成正常的逻辑无法被执行，同时即便是大量的SYN包也可以将CPU爆满</li>
</ul>
<h4><a id="tcp-fast-open" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tcp Fast Open</h4>
<h5><a id="%E5%BC%80%E5%90%AF" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>开启</h5>
<pre><code class="language-plain_text">服务器配置 echo 3 &gt; /proc/sys/net/ipv4/tcp_fastopen系统开启TFO功能
</code></pre>
<ul>
<li>0: 关闭</li>
<li>1: 作为客户端时可以使用 TFO</li>
<li>2: 作为服务器时可以使用 TFO</li>
<li>3: 无论作为客户端还是服务器，都可以使用 TFO</li>
<li>ip tcp_metrics show | grep &quot;fo_cookie&quot; 查看cookie</li>
</ul>
<h5><a id="%E6%88%AA%E5%9B%BE" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>截图</h5>
<ul>
<li><img src="media/15601259183343/15642728044011.jpg" alt="" style="width:1617px;" /></li>
<li>为防止带数据的 SYN 攻击，限制最大长度，指定 TFO 连接队列的最大长度</li>
<li>减少Cpu消耗</li>
<li>客户端的TFOcookie多长时间后删除，谁来维护和删除？</li>
<li>nginx的TFO队列具体是什么意思？队列满了会怎样？数值设定多少合适？</li>
</ul>
<h5><a id="tfo%E5%8E%9F%E7%90%86" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>TFO原理</h5>
<ul>
<li>客户端发送SYN包，包尾加一个FOC请求，只有4个字节。</li>
<li>服务端受到FOC请求，验证后根据来源ip地址声称cookie(8个字节)，将这个COOKIE加载SYN+ACK包的末尾发送回去。</li>
<li>客户端缓存住获取到的Cookie 可以给下一次使用。</li>
<li>下一次请求开始，客户端发送SYN包，这时候后面带上缓存的COOKIE，然后就是正式发送的数据。</li>
<li>服务器端验证COOKIE正确，将数据交给上层应用处理得到相应结果，然后在发送SYN+ACK时，不再等待客户端的ACK确认，即开始发送相应数据。</li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2019-10-03T16:49:30+08:00" itemprop="datePublished">2019/10/03 16:49 下午</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98.html'>Linux性能优化实战</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="15700925706491.html" itemprop="url">
		Redis 性能调优</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h4><a id="%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>问题描述</h4>
<ul>
<li>Can't save in background: fork: Cannot allocate memory</li>
<li>maxmemory10 G-，这个选项非常重要，它用来指定 Redis 可使用的最大内存，Redis 在启动时会把数据加载到内存中，达到最大内存后，Redis 会先尝试清除已到期或即将到期的 Key，当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。</li>
</ul>
<h4><a id="procsysvmovercommit-memory" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>/proc/sys/vm/overcommit_memory</h4>
<ul>
<li>0, 默认值，表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。</li>
<li>1, 表示内核允许分配所有的物理内存，而不管当前的内存状态如何</li>
<li>2, 表示内核允许分配超过所有物理内存和交换空间总和的内存。</li>
</ul>
<h4><a id="%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>问题解决</h4>
<ul>
<li>我们操作系统物理内存是 16 G, redis 主进程占用了最大 10 G 内存，而 fork 子进程也需要 10 G 的内存，这样，redis 总共就需要 20 GB 内存了，而操作系统只有 16 GB 物理内存，肯定会报内存无法分配。</li>
<li>修改maxmemory为小于物理内存的一半</li>
<li>增加服务器物理内存</li>
</ul>
<h4><a id="redis" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>redis</h4>
<ul>
<li>config get auto-aof-rewrite-min-size</li>
<li>config get auto-aof-rewrite-percentage</li>
<li></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2019-10-03T15:55:16+08:00" itemprop="datePublished">2019/10/03 15:55 下午</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98.html'>Linux性能优化实战</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="15700893160219.html" itemprop="url">
		网卡中断过高优化</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h4><a id="%E8%BD%AF%E7%A1%AC%E4%B8%AD%E6%96%AD%E5%8C%BA%E5%88%AB" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>软硬中断区别</h4>
<ul>
<li>(1) 硬中断是有外设硬件发出的，需要有中断控制器参与，而软中断则通常是由硬中断处理程序或者进程调度程序等软件程序发出的中断信号，无需中断控制器参与。</li>
<li>(2) 硬中断直接以硬件的方式引发，处理速度快。软中断以软件指令之方式适合于对响应速度要求不是特别严格的场景。</li>
<li>(3) 硬中断通过设置 CPU 的屏蔽位可进行屏蔽，软中断则由于是指令之方式给出, 不能屏蔽。</li>
<li>(4)硬中断和软中断均会引起上下文切换(进程/线程之切换），进程切换的过程是差不多的</li>
</ul>
<h4><a id="%E8%AF%8A%E6%96%AD%E4%B8%AD%E6%96%AD" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>诊断中断</h4>
<ul>
<li>top</li>
<li>cat /proc/interrupts | grep ens33 获取中断号</li>
<li>IRQ 号決定了需要被 CPU 处理的优先级，IRQ 号越小意味着被优先执行的级别越高</li>
<li>mpstat -P ALL 2 //查看所有cpu核的状态信息</li>
<li>cat /proc/irq/19/smp_affinity</li>
<li>cat /proc/irq/19/smp_affinity_list 查看网卡中断集中在哪个cpu上</li>
<li>echo 1 &gt; /proc/irq/19/smp_affinity_list 设置网卡中断亲和</li>
</ul>
<h4><a id="%E9%85%8D%E7%BD%AErps%E7%BB%91%E5%AE%9A%E7%BD%91%E5%8D%A1%E9%98%9F%E5%88%97%E5%88%B0-cpu" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>配置 RPS 绑定网卡队列到 CPU</h4>
<ul>
<li>echo 0,1 &gt; /proc/irq/19/smp_affinity_list 仍然会导致网卡中断集中在一个cpu上</li>
</ul>
<pre><code class="language-plain_text">echo f &gt; /sys/class/net/ens33/queues/rx-0/rps_cpus
sysctl net.core.rps_sock_flow_entries=32768
echo 32678 &gt; /sys/class/net/ens33/queues/rx-0/rps_flow_cnt
</code></pre>
<ul>
<li>软件层面模拟实现硬件的多队列网卡功能。</li>
</ul>
<h4><a id="%E4%BD%BF%E7%94%A8irqbalance%E6%9C%8D%E5%8A%A1" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>使用IRQBalance服务</h4>
<h4><a id="rss" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>RSS</h4>
<ul>
<li>RSS (Receive Side Scaling）是网卡的硬件特性，实现了多队列。通过多队列网卡驱动加载，就可以获取网卡型号，得到网卡的硬件队列数量，并结合 CPU 核的数量，最终得出所要激活的网卡队列的数量。</li>
<li>ethtool -l eth0</li>
<li>ethtool -L eth0 combined num//最多支持的队列数目</li>
<li>手动绑定,获取网卡的中断号</li>
<li>cat /proc/interrupts | awk '{print $1, $NF}' | grep eth0-TxRx</li>
<li>echo 中断号 &gt; /proc/irq/19/smp_affinity_list</li>
</ul>
<h4><a id="%E5%A6%82%E6%9E%9C%E9%98%9F%E5%88%97%E6%95%B0%E7%9B%AE%E5%B0%8F%E4%BA%8Ecpu%E6%95%B0%E7%9B%AE" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>如果队列数目小于cpu数目</h4>
<ul>
<li>如果手动绑定 CPU 与中断号ーー对应，就会出现软中断负载跑在 0-7 核上，8-1 5 核不处理软中断的情况，这样一来，CPU 的 0-7 核负载依然会很高。</li>
<li>RFS (Receive Flow Steering）是 RPS 的扩展，由于 RPS 只是单纯的把数据包均衡到不同的 CPU 上，此时如果应用程序所在 CPU 和中断处理的 CPU 不在同个核，将会对 CPU Cache 影响很大，RFS 的作用就是将应用程序和软中断处理分配到同一个 CPU 上</li>
<li>在多队列情况下，rps_flow_cntl 的值建议设为 rps_sock_flow_entries 除以 N，其中 N 是设备中接收队列的数量。例如，如果 rps flow_entries 设为 32768, 并且有 8 个配置接收队列，那么 rps_flow_cnt 就应设为 4096</li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2019-01-28T09:19:05+08:00" itemprop="datePublished">2019/01/28 09:19 上午</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98.html'>Linux性能优化实战</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="15486383451378.html" itemprop="url">
		Redis延迟高</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h4><a id="strace" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>strace</h4>
<ul>
<li>strace -f -T -tt -p pid</li>
<li>-f 表示跟踪子进程和子线程，-T 表示显示系统调用的时长，-tt 表示显示跟踪时间</li>
<li>PID=$(docker inspect --format {{.State.Pid}} app)</li>
</ul>
<h4><a id="nsenter" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>nsenter</h4>
<ul>
<li>nsenter --target $PID --net -- lsof -i</li>
<li>进程iowait高，磁盘iowait不高，说明是单个进程使用了一些blocking的磁盘打开方式，比如每次都fsync</li>
<li>strace -f -e指定系统调用</li>
<li></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2019-02-13T10:15:03+08:00" itemprop="datePublished">2019/02/13 10:15 上午</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98.html'>Linux性能优化实战</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="15500241034354.html" itemprop="url">
		评估系统的网络性能</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h4><a id="%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>性能测试</h4>
<ul>
<li>带宽</li>
<li>吞吐量</li>
<li>延迟</li>
<li>PPS</li>
<li></li>
</ul>
<h4><a id="%E5%90%84%E5%8D%8F%E8%AE%AE%E5%B1%82%E7%9A%84%E6%80%A7%E8%83%BD" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>各协议层的性能</h4>
<ul>
<li>web应用层 测试http/https</li>
<li>服务器 tcp/udp</li>
<li>交换机和路由器 PPS 网络层的转发性能</li>
</ul>
<h5><a id="%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%B1%82" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>网络接口层</h5>
<ul>
<li>pktgen测试PPS</li>
</ul>
<h4><a id="tcp%E5%92%8Cudp" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>TCP和UDP</h4>
<ul>
<li>iperf</li>
<li>netperf</li>
</ul>
<h4><a id="http" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>http</h4>
<ul>
<li>ab</li>
<li>webbench</li>
</ul>
<h4><a id="%E5%BA%94%E7%94%A8%E8%B4%9F%E8%BD%BD%E8%AF%B7%E6%B1%82" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>应用负载请求</h4>
<ul>
<li>wrk</li>
<li></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2019-01-22T17:05:42+08:00" itemprop="datePublished">2019/01/22 17:05 下午</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98.html'>Linux性能优化实战</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="15481479427093.html" itemprop="url">
		IO延迟很高</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h4><a id="%E8%BF%BD%E8%B8%AA%E6%B5%81%E7%A8%8B" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>追踪流程</h4>
<ul>
<li>top</li>
<li>iowait</li>
<li>iostat -d -x 1</li>
<li>pidstat -d 1</li>
<li>strace -fp pid</li>
</ul>
<h4><a id="filetop" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>filetop</h4>
<ul>
<li>主要跟踪内核中文件的读写情况，并输出线程 ID（TID）、读写大小、读写类型以及文件名称。</li>
<li>eBPF内核追踪的原理</li>
</ul>
<h4><a id="opensnoop" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>opensnoop</h4>
<ul>
<li>动态追踪内核中的open系统调用</li>
</ul>
<h4><a id="%E8%BF%BD%E8%B8%AA%E6%B5%81%E7%A8%8B" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>追踪流程</h4>
<ul>
<li>top</li>
<li>iostat</li>
<li>pidstat</li>
<li>strace</li>
<li>lsof</li>
<li>filetop</li>
<li>opensnoop</li>
<li>通过文件找到正在操作的数据库和表</li>
<li></li>
</ul>


			
			
		</div>

	</article>
  

</div>
<nav id="pagenavi">
	 <a class="prev" href="Linux性能优化实战.html">Prev</a>  
	 <a class="next" href="Linux性能优化实战_2.html">Next</a> 
	<div class="center"><a href="archives.html">Blog Archives</a></div>

</nav>

</div>



        </div>
			<footer id="footer" class="inner">Copyright &copy; 2014
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; 
Theme by <a href="http://shashankmehta.in/archive/2012/greyshade.html">Shashank Mehta</a>
      </footer>
		</div>
	</div>

  
    



</body>
</html>